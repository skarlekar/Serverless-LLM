MVP2 is a a serverless application that accepts a large body of text from the user and extracts structured knowledge identifying objects, entities, locations and their relationship between each other from the given unstructured text using a Large Language Model (LLM). 

The structured knowledge will be generated by the LLM in form of a JSON that will be then converted to Apache TinkerPop Gremlin data format to render the knowledge as a graph for visualization.

The logic for the application is as follows:

1. A Streamlit Python application will accept the user input using a chat module. The chat module will have Memory Buffer enabled for it to remember the conversation.
2. The Streamlit application will call a Titan LLM model using AWS Bedrock runtime.
3. The prompt for the LLM model will contain instructions to extract entities and relationships in JSON format. The format of the output JSON will be provided in the prompt in order to capture the vertices and edges of a Gremlin data graph.
4.  The JSON response from the LLM will be used to generate two separate files, one for the Vertex CSV file and another for the Edge CSV file.
5. The Vertex CSV file will contain the ‘id’ and ‘label’ field. Multiple label values are allowed, separated by semicolons (;).
6. The Edge CSV file will contain the ‘id’, ‘from’, ‘to’ and the ‘label’ for the edge. Edges can only have a single label.
7. Load the Vertex and Edge CSV file in AWS Neptune Graph database and get a reference-id.
8.  Use the reference for the graph data in AWS Neptune to render an interactive graph.

More information regarding Amazon Neptune Gremlin Data Format can be found here: https://docs.aws.amazon.com/neptune/latest/userguide/bulk-load-tutorial-format-gremlin.html